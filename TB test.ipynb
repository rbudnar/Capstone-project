{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.709710</td>\n",
       "      <td>0.723537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.542104</td>\n",
       "      <td>0.304981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.130214</td>\n",
       "      <td>0.367120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.645674</td>\n",
       "      <td>1.118153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.153306</td>\n",
       "      <td>1.521124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.135825</td>\n",
       "      <td>-1.635160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.625411</td>\n",
       "      <td>0.973593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.416999</td>\n",
       "      <td>2.119942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.433271</td>\n",
       "      <td>1.177496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.664065</td>\n",
       "      <td>0.890511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1.342268</td>\n",
       "      <td>-0.486702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.485547</td>\n",
       "      <td>0.202034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.705167</td>\n",
       "      <td>-0.489830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.778501</td>\n",
       "      <td>-1.233038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.838741</td>\n",
       "      <td>-0.489614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.282838</td>\n",
       "      <td>-0.346393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.173557</td>\n",
       "      <td>0.742885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.212585</td>\n",
       "      <td>-2.282893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.774948</td>\n",
       "      <td>-0.127353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.139049</td>\n",
       "      <td>-0.148518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.960168</td>\n",
       "      <td>1.412368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.163620</td>\n",
       "      <td>-0.804603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-1.990163</td>\n",
       "      <td>-0.517205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.509618</td>\n",
       "      <td>1.806527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-1.035167</td>\n",
       "      <td>-0.021043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.696966</td>\n",
       "      <td>-1.475269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-1.502049</td>\n",
       "      <td>1.565011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.402403</td>\n",
       "      <td>0.189401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.850629</td>\n",
       "      <td>-0.216075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.517316</td>\n",
       "      <td>0.659066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>-0.348475</td>\n",
       "      <td>-0.673135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>-0.622381</td>\n",
       "      <td>-0.413491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.677240</td>\n",
       "      <td>-1.158696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.628523</td>\n",
       "      <td>0.608556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>-0.859489</td>\n",
       "      <td>-0.318489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.625882</td>\n",
       "      <td>-1.916091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.409679</td>\n",
       "      <td>1.182227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>-1.120429</td>\n",
       "      <td>-0.265067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1.456477</td>\n",
       "      <td>-0.622403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>-0.299827</td>\n",
       "      <td>0.151848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.301295</td>\n",
       "      <td>-0.104351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>-0.534373</td>\n",
       "      <td>-0.005354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>-0.778139</td>\n",
       "      <td>1.060847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2.022870</td>\n",
       "      <td>-0.853534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.720868</td>\n",
       "      <td>0.258237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>-0.130547</td>\n",
       "      <td>-1.620628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>-1.524758</td>\n",
       "      <td>-1.009975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.311133</td>\n",
       "      <td>0.148015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.079148</td>\n",
       "      <td>-0.455914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.513941</td>\n",
       "      <td>0.168760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.157479</td>\n",
       "      <td>0.394418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.055104</td>\n",
       "      <td>0.104022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.204690</td>\n",
       "      <td>-0.296339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>-0.995372</td>\n",
       "      <td>-0.714124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>-2.075244</td>\n",
       "      <td>-0.443334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1.614643</td>\n",
       "      <td>-0.310726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.796979</td>\n",
       "      <td>0.805427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.928755</td>\n",
       "      <td>1.648041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-1.114468</td>\n",
       "      <td>-0.816009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.213022</td>\n",
       "      <td>-0.561090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1\n",
       "0  -0.709710  0.723537\n",
       "1   0.542104  0.304981\n",
       "2  -0.130214  0.367120\n",
       "3  -1.645674  1.118153\n",
       "4   1.153306  1.521124\n",
       "..       ...       ...\n",
       "95  1.614643 -0.310726\n",
       "96  0.796979  0.805427\n",
       "97 -0.928755  1.648041\n",
       "98 -1.114468 -0.816009\n",
       "99  0.213022 -0.561090\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(100, 2))\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True, False,\n",
       "        True,  True,  True, False,  True,  True, False,  True,  True,\n",
       "        True,  True, False,  True,  True,  True, False,  True,  True,\n",
       "        True,  True, False, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        True,  True,  True, False,  True,  True,  True,  True, False,\n",
       "        True,  True, False,  True, False,  True,  True,  True,  True,\n",
       "        True, False,  True, False, False, False,  True,  True, False,\n",
       "        True])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msk = np.random.rand(len(df)) < 0.8\n",
    "msk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.709710</td>\n",
       "      <td>0.723537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.542104</td>\n",
       "      <td>0.304981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.130214</td>\n",
       "      <td>0.367120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.645674</td>\n",
       "      <td>1.118153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.153306</td>\n",
       "      <td>1.521124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.135825</td>\n",
       "      <td>-1.635160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.625411</td>\n",
       "      <td>0.973593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.416999</td>\n",
       "      <td>2.119942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.664065</td>\n",
       "      <td>0.890511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1.342268</td>\n",
       "      <td>-0.486702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.485547</td>\n",
       "      <td>0.202034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.778501</td>\n",
       "      <td>-1.233038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.838741</td>\n",
       "      <td>-0.489614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.282838</td>\n",
       "      <td>-0.346393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.173557</td>\n",
       "      <td>0.742885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.212585</td>\n",
       "      <td>-2.282893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.774948</td>\n",
       "      <td>-0.127353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.139049</td>\n",
       "      <td>-0.148518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.960168</td>\n",
       "      <td>1.412368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.163620</td>\n",
       "      <td>-0.804603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-1.990163</td>\n",
       "      <td>-0.517205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.509618</td>\n",
       "      <td>1.806527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-1.035167</td>\n",
       "      <td>-0.021043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.696966</td>\n",
       "      <td>-1.475269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-1.502049</td>\n",
       "      <td>1.565011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.402403</td>\n",
       "      <td>0.189401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.850629</td>\n",
       "      <td>-0.216075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.517316</td>\n",
       "      <td>0.659066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.435895</td>\n",
       "      <td>-0.821639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.268425</td>\n",
       "      <td>1.075839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>-0.186577</td>\n",
       "      <td>0.219973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.429079</td>\n",
       "      <td>-0.925813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>-0.446849</td>\n",
       "      <td>-0.405534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.966761</td>\n",
       "      <td>2.448092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>-1.933272</td>\n",
       "      <td>0.303733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1.432028</td>\n",
       "      <td>-0.461284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>-0.551542</td>\n",
       "      <td>0.722863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>-1.265587</td>\n",
       "      <td>0.068759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>-0.510170</td>\n",
       "      <td>1.359300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>-0.348475</td>\n",
       "      <td>-0.673135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>-0.622381</td>\n",
       "      <td>-0.413491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.677240</td>\n",
       "      <td>-1.158696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.628523</td>\n",
       "      <td>0.608556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>-0.859489</td>\n",
       "      <td>-0.318489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.409679</td>\n",
       "      <td>1.182227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>-1.120429</td>\n",
       "      <td>-0.265067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1.456477</td>\n",
       "      <td>-0.622403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>-0.299827</td>\n",
       "      <td>0.151848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>-0.534373</td>\n",
       "      <td>-0.005354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>-0.778139</td>\n",
       "      <td>1.060847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.720868</td>\n",
       "      <td>0.258237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>-1.524758</td>\n",
       "      <td>-1.009975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.311133</td>\n",
       "      <td>0.148015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.079148</td>\n",
       "      <td>-0.455914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.513941</td>\n",
       "      <td>0.168760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.157479</td>\n",
       "      <td>0.394418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.204690</td>\n",
       "      <td>-0.296339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.796979</td>\n",
       "      <td>0.805427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.928755</td>\n",
       "      <td>1.648041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.213022</td>\n",
       "      <td>-0.561090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1\n",
       "0  -0.709710  0.723537\n",
       "1   0.542104  0.304981\n",
       "2  -0.130214  0.367120\n",
       "3  -1.645674  1.118153\n",
       "4   1.153306  1.521124\n",
       "..       ...       ...\n",
       "90  0.157479  0.394418\n",
       "92  0.204690 -0.296339\n",
       "96  0.796979  0.805427\n",
       "97 -0.928755  1.648041\n",
       "99  0.213022 -0.561090\n",
       "\n",
       "[80 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.433271</td>\n",
       "      <td>1.177496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.705167</td>\n",
       "      <td>-0.489830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.132363</td>\n",
       "      <td>0.153279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2.964639</td>\n",
       "      <td>-0.480044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-0.619886</td>\n",
       "      <td>-0.766234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3.073198</td>\n",
       "      <td>0.020728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-0.035183</td>\n",
       "      <td>-1.684422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1.322598</td>\n",
       "      <td>0.154975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>-0.038254</td>\n",
       "      <td>1.037313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>-0.614838</td>\n",
       "      <td>-0.701317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>-0.165813</td>\n",
       "      <td>0.386450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.625882</td>\n",
       "      <td>-1.916091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.301295</td>\n",
       "      <td>-0.104351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2.022870</td>\n",
       "      <td>-0.853534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>-0.130547</td>\n",
       "      <td>-1.620628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.055104</td>\n",
       "      <td>0.104022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>-0.995372</td>\n",
       "      <td>-0.714124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>-2.075244</td>\n",
       "      <td>-0.443334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1.614643</td>\n",
       "      <td>-0.310726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-1.114468</td>\n",
       "      <td>-0.816009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1\n",
       "8  -1.433271  1.177496\n",
       "12  0.705167 -0.489830\n",
       "32  1.132363  0.153279\n",
       "35  2.964639 -0.480044\n",
       "39 -0.619886 -0.766234\n",
       "42  3.073198  0.020728\n",
       "47 -0.035183 -1.684422\n",
       "51  1.322598  0.154975\n",
       "56 -0.038254  1.037313\n",
       "57 -0.614838 -0.701317\n",
       "67 -0.165813  0.386450\n",
       "75  0.625882 -1.916091\n",
       "80  0.301295 -0.104351\n",
       "83  2.022870 -0.853534\n",
       "85 -0.130547 -1.620628\n",
       "91  0.055104  0.104022\n",
       "93 -0.995372 -0.714124\n",
       "94 -2.075244 -0.443334\n",
       "95  1.614643 -0.310726\n",
       "98 -1.114468 -0.816009"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = df[msk]\n",
    "test = df[~msk]\n",
    "display(train)\n",
    "display(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "#https://medium.com/@shaolinkhoa/install-tensorflow-gpu-2-0-alpha-on-anaconda-for-windows-10-ubuntu-ced099010b21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.0.0-beta1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow import keras\n",
    "# import keras\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "    \"This notebook requires TensorFlow 2.0 or above.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 1000\n",
    "# 80% of the data is for training.\n",
    "train_pct = 0.8\n",
    "\n",
    "train_size = int(data_size * train_pct)\n",
    "\n",
    "# Create some input data between -1 and 1 and randomize it.\n",
    "x = np.linspace(-1, 1, data_size)\n",
    "np.random.shuffle(x)\n",
    "\n",
    "# Generate the output data.\n",
    "# y = 0.5x + 2 + noise\n",
    "y = 0.5 * x + 2 + np.random.normal(0, 0.05, (data_size, ))\n",
    "\n",
    "# Split into test and train pairs.\n",
    "x_train, y_train = x[:train_size], y[:train_size]\n",
    "x_test, y_test = x[train_size:], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32.002335 ]\n",
      " [14.502413 ]\n",
      " [ 3.0024674]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict([60, 25, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ... With default parameters, this takes less than 10 seconds.\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/100\n",
      "800/800 [==============================] - 0s 428us/sample - loss: 4.3546 - accuracy: 0.0000e+00 - val_loss: 0.1241 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 0.1198 - accuracy: 0.0000e+00 - val_loss: 0.0309 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 0s 10us/sample - loss: 0.0322 - accuracy: 0.0000e+00 - val_loss: 0.0096 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 0s 9us/sample - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 0s 10us/sample - loss: 0.0037 - accuracy: 0.0000e+00 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 0s 9us/sample - loss: 0.0026 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 0s 9us/sample - loss: 0.0024 - accuracy: 0.0000e+00 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 0s 9us/sample - loss: 0.0024 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 0s 10us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 0s 9us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 0s 9us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 0s 7us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 0s 10us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 0s 7us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 0s 10us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 0s 11us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 0s 9us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 0s 11us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 0s 9us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 0s 11us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 0s 9us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 0s 10us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 0s 10us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 0s 10us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 0s 11us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 0s 9us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 0s 11us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 0s 10us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 0s 9us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 0s 11us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 0s 9us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 0s 10us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 0s 10us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 0s 11us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 0s 9us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 0s 10us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 0s 11us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 0s 10us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 0s 11us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 0s 12us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 0s 9us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 0s 11us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 0s 14us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 0s 12us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 0s 11us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 0s 11us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 0s 10us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 0s 9us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 0s 10us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 0s 10us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 0s 12us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 0s 9us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 0s 10us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "800/800 [==============================] - 0s 10us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 0s 11us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 0s 19us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 0s 12us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 0s 9us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 0s 12us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 0s 12us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 0s 11us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 0s 12us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 0s 14us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 0s 11us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 0s 9us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 0s 12us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 0s 10us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 0s 12us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 0s 11us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 0s 9us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 0s 9us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 0s 7us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 0s 9us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 0s 11us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 0s 12us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 0s 12us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 0s 15us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 0s 7us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 0s 9us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 0s 9us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 0s 9us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 0s 9us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "800/800 [==============================] - 0s 9us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 0s 9us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 0s 10us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 0s 11us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 0s 9us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 0s 9us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 0s 10us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 0s 11us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 0s 10us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 0s 9us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 0s 10us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 0s 9us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 0s 11us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - 0s 11us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "800/800 [==============================] - 0s 12us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "800/800 [==============================] - 0s 11us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "800/800 [==============================] - 0s 11us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "800/800 [==============================] - 0s 16us/sample - loss: 0.0023 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
      "Average test loss:  0.04741664073895663\n"
     ]
    }
   ],
   "source": [
    "# logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logdir = os.path.join(\"logs\", \"scalars\", datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(16, input_dim=1),\n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='mse', # keras.losses.mean_squared_error\n",
    "    optimizer=keras.optimizers.SGD(lr=0.2),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "print(\"Training ... With default parameters, this takes less than 10 seconds.\")\n",
    "training_history = model.fit(\n",
    "    x_train, # input\n",
    "    y_train, # output\n",
    "    batch_size=train_size,\n",
    "    verbose=1, # Suppress chatty output; use Tensorboard instead\n",
    "    epochs=100,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[tensorboard_callback],\n",
    ")\n",
    "\n",
    "print(\"Average test loss: \", np.average(training_history.history['loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = os.path.join(\"logs\", \"scalars\", datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "file_writer = tf.summary.create_file_writer(os.path.join(logdir, \"metrics\"))\n",
    "file_writer.set_as_default()\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "  \"\"\"\n",
    "  Returns a custom learning rate that decreases as epochs progress.\n",
    "  \"\"\"\n",
    "  learning_rate = 0.2\n",
    "  if epoch > 10:\n",
    "    learning_rate = 0.02\n",
    "  if epoch > 20:\n",
    "    learning_rate = 0.01\n",
    "  if epoch > 50:\n",
    "    learning_rate = 0.005\n",
    "\n",
    "  tf.summary.scalar('learning rate', data=learning_rate, step=epoch)\n",
    "  return learning_rate\n",
    "\n",
    "lr_callback = keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(16, input_dim=1),\n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='mse', # keras.losses.mean_squared_error\n",
    "    optimizer=keras.optimizers.SGD(),\n",
    ")\n",
    "\n",
    "training_history = model.fit(\n",
    "    x_train, # input\n",
    "    y_train, # output\n",
    "    batch_size=train_size,\n",
    "    verbose=0, # Suppress chatty output; use Tensorboard instead\n",
    "    epochs=100,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[tensorboard_callback, lr_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32.002335 ]\n",
      " [14.502413 ]\n",
      " [ 3.0024674]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict([60, 25, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
