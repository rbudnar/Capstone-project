{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "import seaborn as sb\n",
    "%matplotlib inline\n",
    "# from keras.applications.densenet import DenseNet121\n",
    "\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense, Add, Concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "import timeit\n",
    "import os\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "from math import ceil\n",
    "from main_v2 import (generate_dataframe_from_csv_horizontal, generate_dataframe_from_csv_vertical, \n",
    "                         get_model_inputs, create_multi_generator, build_model, ConvBlock)\n",
    "# https://github.com/keras-team/keras/issues/4161#issuecomment-366031228\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "                                    # (nothing gets printed in Jupyter, only if you run it standalone)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras\n",
    "\n",
    "# import wandb\n",
    "# from wandb.keras import WandbCallback\n",
    "from train import TrainingRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54772 18257 6847 2283\n"
     ]
    }
   ],
   "source": [
    "# df = generate_dataframe_from_csv_vertical(\"train.csv\", inputs=1)\n",
    "# df = generate_dataframe_from_csv_horizontal(\"train.csv\")\n",
    "df = pd.read_csv(\"./train_root.csv\",  dtype={'sirna': object})\n",
    "val_split = 0.25\n",
    "epochs = 20\n",
    "batch_size = 8\n",
    "train_size = int(len(df)*(1-val_split))\n",
    "valid_size = int(len(df)*(val_split))\n",
    "steps = ceil(train_size/batch_size)\n",
    "steps_valid = ceil(valid_size/batch_size)\n",
    "print(train_size, valid_size, steps, steps_valid)\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 224, 224, 32) 2432        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 224, 224, 32) 2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 224, 224, 32) 2432        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 224, 224, 32) 2432        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 224, 224, 32) 2432        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 224, 224, 32) 2432        input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 224, 224, 32) 128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 224, 224, 32) 128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 224, 224, 32) 128         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 224, 224, 32) 128         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 224, 224, 32) 128         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 224, 224, 32) 128         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 112, 112, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 112, 112, 32) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 112, 112, 32) 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 112, 112, 32) 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 112, 112, 32) 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 112, 112, 32) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 112, 112, 64) 18496       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 112, 112, 64) 18496       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 112, 112, 64) 18496       max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 112, 112, 64) 18496       max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 112, 112, 64) 18496       max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 112, 112, 64) 18496       max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 112, 112, 64) 256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 112, 112, 64) 256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 112, 112, 64) 256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 112, 112, 64) 256         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 112, 112, 64) 256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 112, 112, 64) 256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 56, 56, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 56, 56, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 56, 56, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 56, 56, 64)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 56, 56, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, 56, 56, 64)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 56, 56, 128)  73856       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 56, 56, 128)  73856       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 56, 56, 128)  73856       max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 56, 56, 128)  73856       max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 56, 56, 128)  73856       max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 56, 56, 128)  73856       max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 56, 56, 128)  512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 56, 56, 128)  512         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 56, 56, 128)  512         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 56, 56, 128)  512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 56, 56, 128)  512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 56, 56, 128)  512         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 28, 28, 128)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 28, 28, 128)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 28, 28, 128)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 28, 28, 128)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 28, 28, 128)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, 28, 28, 128)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 100352)       0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 100352)       0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 100352)       0           max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 100352)       0           max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 100352)       0           max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 100352)       0           max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 602112)       0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           6021130     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_1 (BatchNormalizatio (None, 10)           40          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10)           0           batch_norm_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 4)            44          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 6,595,294\n",
      "Trainable params: 6,592,586\n",
      "Non-trainable params: 2,708\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#runner = TrainingRunner(filename=\"train_root.csv\", use_multi=True, epochs=epochs, batch_size=batch_size, val_split=val_split, use_wandb=False)\n",
    "runner = TrainingRunner(batch_size=16, filename=\"train_root.csv\", build_cell_model=True)\n",
    "runner.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "3652/3652 [==============================] - 1534s 420ms/step - loss: 0.5498 - acc: 0.9332 - val_loss: 0.6547 - val_acc: 0.9185\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.65471, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "Epoch 2/20\n",
      "3652/3652 [==============================] - 1531s 419ms/step - loss: 1.2889 - acc: 0.9513 - val_loss: 2.5940 - val_acc: 0.5831\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.65471\n",
      "Epoch 3/20\n",
      "3652/3652 [==============================] - 1504s 412ms/step - loss: 0.9401 - acc: 0.9569 - val_loss: 0.8401 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.65471\n",
      "Epoch 4/20\n",
      "3652/3652 [==============================] - 1497s 410ms/step - loss: 0.6348 - acc: 0.9640 - val_loss: 0.4509 - val_acc: 0.9875\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.65471 to 0.45088, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "Epoch 5/20\n",
      "3652/3652 [==============================] - 1499s 410ms/step - loss: 1.0364 - acc: 0.9709 - val_loss: 1.1594 - val_acc: 0.8332\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.45088\n",
      "Epoch 6/20\n",
      "3652/3652 [==============================] - 1526s 418ms/step - loss: 1.5674 - acc: 0.9650 - val_loss: 1.4086 - val_acc: 0.8190\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.45088\n",
      "Epoch 7/20\n",
      "3652/3652 [==============================] - 1507s 413ms/step - loss: 0.8988 - acc: 0.9575 - val_loss: 0.6815 - val_acc: 0.9739\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.45088\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 8/20\n",
      "3652/3652 [==============================] - 1520s 416ms/step - loss: 0.5321 - acc: 0.9637 - val_loss: 0.9201 - val_acc: 0.9012\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.45088\n",
      "Epoch 9/20\n",
      "3652/3652 [==============================] - 1513s 414ms/step - loss: 0.5807 - acc: 0.9687 - val_loss: 1.1446 - val_acc: 0.7635\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.45088\n",
      "Epoch 10/20\n",
      "3652/3652 [==============================] - 1513s 414ms/step - loss: 0.4135 - acc: 0.9745 - val_loss: 0.3968 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.45088 to 0.39677, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "Epoch 11/20\n",
      "3652/3652 [==============================] - 1511s 414ms/step - loss: 0.3269 - acc: 0.9739 - val_loss: 0.4253 - val_acc: 0.9612\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.39677\n",
      "Epoch 12/20\n",
      "3652/3652 [==============================] - 1513s 414ms/step - loss: 0.3663 - acc: 0.9614 - val_loss: 3.0939 - val_acc: 0.4785\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.39677\n",
      "Epoch 13/20\n",
      "3652/3652 [==============================] - 1511s 414ms/step - loss: 0.6379 - acc: 0.9772 - val_loss: 7.2272 - val_acc: 0.2265\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.39677\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 14/20\n",
      "3652/3652 [==============================] - 1516s 415ms/step - loss: 0.2783 - acc: 0.9875 - val_loss: 0.2236 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.39677 to 0.22360, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "Epoch 15/20\n",
      "3652/3652 [==============================] - 1521s 417ms/step - loss: 0.1587 - acc: 0.9828 - val_loss: 0.0982 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.22360 to 0.09822, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "Epoch 16/20\n",
      "3652/3652 [==============================] - 1514s 414ms/step - loss: 0.1523 - acc: 0.9759 - val_loss: 0.0749 - val_acc: 0.9973\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.09822 to 0.07488, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "Epoch 17/20\n",
      "3652/3652 [==============================] - 1525s 418ms/step - loss: 0.1489 - acc: 0.9848 - val_loss: 0.2076 - val_acc: 0.9656\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.07488\n",
      "Epoch 18/20\n",
      "3652/3652 [==============================] - 1513s 414ms/step - loss: 0.1589 - acc: 0.9816 - val_loss: 0.1105 - val_acc: 0.9982\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.07488\n",
      "Epoch 19/20\n",
      "3652/3652 [==============================] - 1507s 413ms/step - loss: 0.1538 - acc: 0.9881 - val_loss: 0.1612 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.07488\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 20/20\n",
      "3652/3652 [==============================] - 1508s 413ms/step - loss: 0.1551 - acc: 0.9906 - val_loss: 0.2989 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.07488\n"
     ]
    }
   ],
   "source": [
    "# runner.train_generator.__getitem__(1)\n",
    "runner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.model.save(\"saved_models\\cell_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 54773 validated image filenames belonging to 1108 classes.\n",
      "Found 18257 validated image filenames belonging to 1108 classes.\n"
     ]
    }
   ],
   "source": [
    "# wandb.init(project=\"testing-ml\")\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, \n",
    "                                   verbose=1, mode='auto', min_delta=0.0001)\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=15)\n",
    "\n",
    "csv_logger = CSVLogger(filename='./training_log.csv',\n",
    "                       separator=',',\n",
    "                       append=True)\n",
    "\n",
    "logdir = os.path.join(\"logs\", datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "\n",
    "(images, trainY) = get_model_inputs(df)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        validation_split=val_split)\n",
    "\n",
    "# train_generator = create_multi_generator(df, train_datagen, \"training\") \n",
    "# valid_generator = create_multi_generator(df, train_datagen, \"validation\") \n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "        df,\n",
    "        directory=\"./\",\n",
    "        x_col=\"img_path\",\n",
    "        y_col=\"sirna\",\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        subset=\"training\",\n",
    "        class_mode='categorical')\n",
    "\n",
    "valid_generator = train_datagen.flow_from_dataframe(\n",
    "        df,\n",
    "        directory=\"./\",\n",
    "        x_col=\"img_path\",\n",
    "        y_col=\"sirna\",\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        subset=\"validation\",\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 64)      4864      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 224, 224, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 112, 112, 128)     512       \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              129000    \n",
      "_________________________________________________________________\n",
      "bn_fc_1 (BatchNormalization) (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1108)              1109108   \n",
      "=================================================================\n",
      "Total params: 1,321,596\n",
      "Trainable params: 1,319,212\n",
      "Non-trainable params: 2,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "1712/1712 [==============================] - 678s 396ms/step - loss: 7.5768 - acc: 0.0012 - val_loss: 16.4520 - val_acc: 8.2160e-04\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 16.45205, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "Epoch 2/20\n",
      "  41/1712 [..............................] - ETA: 9:26 - loss: 7.3360 - acc: 0.0023"
     ]
    }
   ],
   "source": [
    "#https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.from_scratch.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "# WORKERS = 2\n",
    "\n",
    "model.fit_generator(train_generator, \n",
    "                    steps_per_epoch=steps,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=steps_valid,\n",
    "#                     workers=WORKERS, \n",
    "#                     use_multiprocessing=True,\n",
    "                    epochs=epochs, callbacks=[checkpointer,reduceLROnPlat, early, csv_logger, tensorboard_callback], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wandb run python train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard --logdir=logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
