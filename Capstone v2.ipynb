{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "import seaborn as sb\n",
    "%matplotlib inline\n",
    "# from keras.applications.densenet import DenseNet121\n",
    "\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense, Add, Concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "import timeit\n",
    "import os\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "from math import ceil\n",
    "from main_v2 import (generate_dataframe_from_csv_horizontal, generate_dataframe_from_csv_vertical, \n",
    "                         get_model_inputs, create_multi_generator, build_model, ConvBlock)\n",
    "# https://github.com/keras-team/keras/issues/4161#issuecomment-366031228\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "                                    # (nothing gets printed in Jupyter, only if you run it standalone)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras\n",
    "\n",
    "# import wandb\n",
    "# from wandb.keras import WandbCallback\n",
    "from train import TrainingRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54772 18257 1712 571\n"
     ]
    }
   ],
   "source": [
    "# df = generate_dataframe_from_csv_vertical(\"train.csv\", inputs=1)\n",
    "# df = generate_dataframe_from_csv_horizontal(\"train.csv\")\n",
    "df = pd.read_csv(\"./train_1.csv\",  dtype={'sirna': object})\n",
    "val_split = 0.25\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "train_size = int(len(df)*(1-val_split))\n",
    "valid_size = int(len(df)*(val_split))\n",
    "steps = ceil(train_size/batch_size)\n",
    "steps_valid = ceil(valid_size/batch_size)\n",
    "print(train_size, valid_size, steps, steps_valid)\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 58424 validated image filenames belonging to 1108 classes.\n",
      "Found 14606 validated image filenames belonging to 1108 classes.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\keras_applications\\resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94658560/94653016 [==============================] - 6s 0us/step\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              100353000 \n",
      "_________________________________________________________________\n",
      "bn_fc_1 (BatchNormalization) (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1108)              1109108   \n",
      "=================================================================\n",
      "Total params: 125,053,820\n",
      "Trainable params: 101,464,108\n",
      "Non-trainable params: 23,589,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# runner = TrainingRunner(filename=\"train_root.csv\", use_multi=True, epochs=epochs, batch_size=batch_size, val_split=val_split, use_wandb=False)\n",
    "runner = TrainingRunner(batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runner.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "7303/7303 [==============================] - 772s 106ms/step - loss: 7.2250 - acc: 8.2158e-04 - val_loss: 14.9397 - val_acc: 8.2158e-04\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 14.93974, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "Epoch 2/20\n",
      "7303/7303 [==============================] - 717s 98ms/step - loss: 7.0213 - acc: 0.0012 - val_loss: 12.9612 - val_acc: 8.9005e-04\n",
      "\n",
      "Epoch 00002: val_loss improved from 14.93974 to 12.96116, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "Epoch 3/20\n",
      "7303/7303 [==============================] - 706s 97ms/step - loss: 6.9984 - acc: 0.0016 - val_loss: 13.0310 - val_acc: 8.9005e-04\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 12.96116\n",
      "Epoch 4/20\n",
      "7303/7303 [==============================] - 707s 97ms/step - loss: 6.9677 - acc: 0.0017 - val_loss: 12.2175 - val_acc: 9.5851e-04\n",
      "\n",
      "Epoch 00004: val_loss improved from 12.96116 to 12.21754, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "Epoch 5/20\n",
      "7303/7303 [==============================] - 707s 97ms/step - loss: 6.9532 - acc: 0.0019 - val_loss: 12.8345 - val_acc: 7.5312e-04\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 12.21754\n",
      "Epoch 6/20\n",
      "7303/7303 [==============================] - 709s 97ms/step - loss: 6.9381 - acc: 0.0019 - val_loss: 12.3406 - val_acc: 6.8465e-04\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 12.21754\n",
      "Epoch 7/20\n",
      "7303/7303 [==============================] - 737s 101ms/step - loss: 6.9315 - acc: 0.0022 - val_loss: 11.7631 - val_acc: 8.2158e-04\n",
      "\n",
      "Epoch 00007: val_loss improved from 12.21754 to 11.76308, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "Epoch 8/20\n",
      "7303/7303 [==============================] - 725s 99ms/step - loss: 6.9194 - acc: 0.0025 - val_loss: 12.2339 - val_acc: 0.0010\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 11.76308\n",
      "Epoch 9/20\n",
      " 668/7303 [=>............................] - ETA: 10:17 - loss: 6.9120 - acc: 0.0030"
     ]
    }
   ],
   "source": [
    "runner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 54773 validated image filenames belonging to 1108 classes.\n",
      "Found 18257 validated image filenames belonging to 1108 classes.\n"
     ]
    }
   ],
   "source": [
    "# wandb.init(project=\"testing-ml\")\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, \n",
    "                                   verbose=1, mode='auto', min_delta=0.0001)\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=15)\n",
    "\n",
    "csv_logger = CSVLogger(filename='./training_log.csv',\n",
    "                       separator=',',\n",
    "                       append=True)\n",
    "\n",
    "logdir = os.path.join(\"logs\", datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "\n",
    "(images, trainY) = get_model_inputs(df)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        validation_split=val_split)\n",
    "\n",
    "# train_generator = create_multi_generator(df, train_datagen, \"training\") \n",
    "# valid_generator = create_multi_generator(df, train_datagen, \"validation\") \n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "        df,\n",
    "        directory=\"./\",\n",
    "        x_col=\"img_path\",\n",
    "        y_col=\"sirna\",\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        subset=\"training\",\n",
    "        class_mode='categorical')\n",
    "\n",
    "valid_generator = train_datagen.flow_from_dataframe(\n",
    "        df,\n",
    "        directory=\"./\",\n",
    "        x_col=\"img_path\",\n",
    "        y_col=\"sirna\",\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        subset=\"validation\",\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 64)      4864      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 224, 224, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 112, 112, 128)     512       \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              129000    \n",
      "_________________________________________________________________\n",
      "bn_fc_1 (BatchNormalization) (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1108)              1109108   \n",
      "=================================================================\n",
      "Total params: 1,321,596\n",
      "Trainable params: 1,319,212\n",
      "Non-trainable params: 2,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "1712/1712 [==============================] - 678s 396ms/step - loss: 7.5768 - acc: 0.0012 - val_loss: 16.4520 - val_acc: 8.2160e-04\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 16.45205, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "Epoch 2/20\n",
      "  41/1712 [..............................] - ETA: 9:26 - loss: 7.3360 - acc: 0.0023"
     ]
    }
   ],
   "source": [
    "#https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.from_scratch.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "# WORKERS = 2\n",
    "\n",
    "model.fit_generator(train_generator, \n",
    "                    steps_per_epoch=steps,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=steps_valid,\n",
    "#                     workers=WORKERS, \n",
    "#                     use_multiprocessing=True,\n",
    "                    epochs=epochs, callbacks=[checkpointer,reduceLROnPlat, early, csv_logger, tensorboard_callback], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wandb run python train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard --logdir=logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
